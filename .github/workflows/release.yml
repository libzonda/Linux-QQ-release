name: Scraping and Release

on:
  schedule:
    - cron: '0 */12 * * *'
  workflow_dispatch:

permissions:
  contents: write
  packages: write

jobs:
  scrape-and-release:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure DNS and Fetch Config
        id: fetch_config
        run: |
          # Robust DNS resolution using Tencent DNS
          CDN_IP=$(nslookup cdn-go.cn 119.29.29.29 | grep -A 1 "Non-authoritative answer" | grep "Address" | head -n 1 | awk '{print $2}')
          IM_IP=$(nslookup im.qq.com 119.29.29.29 | grep -A 1 "Non-authoritative answer" | grep "Address" | head -n 1 | awk '{print $2}')
          DL_IP=$(nslookup dldir1v6.qq.com 119.29.29.29 | grep -A 1 "Non-authoritative answer" | grep "Address" | head -n 1 | awk '{print $2}')
          
          echo "Settings hosts..."
          sudo echo "$CDN_IP cdn-go.cn" | sudo tee -a /etc/hosts
          sudo echo "$IM_IP im.qq.com" | sudo tee -a /etc/hosts
          sudo echo "$DL_IP dldir1v6.qq.com" | sudo tee -a /etc/hosts
          
          echo "Fetching linuxConfig.js directly..."
          # Use a random param to bust server-side cache
          T=$(date +%s)
          # Use X-Forwarded-For just in case as an additional hint for domestic routing
          CONFIG_URL="https://cdn-go.cn/qq-web/im.qq.com_new/latest/rainbow/linuxConfig.js?t=$T"
          echo "URL: $CONFIG_URL"
          
          curl -s -L -H "X-Forwarded-For: 183.60.209.130" "$CONFIG_URL" -o linuxConfig.js
          
          echo "--- Content Preview ---"
          head -c 200 linuxConfig.js
          echo -e "\n--- End Preview ---"
          
          VERSION=$(grep -o '"version":"[^"]*"' linuxConfig.js | head -n 1 | cut -d'"' -f4)
          echo "Detected Version: $VERSION"
          echo "VERSION=$VERSION" >> $GITHUB_OUTPUT
          echo "$VERSION" > version.txt
          
          # Extract all download URLs
          grep -o 'https://dldir1v6.qq.com/[^"]*' linuxConfig.js | sort | uniq > links.txt
          
          echo "Links found:"
          cat links.txt
          
          # Prepare links.md for release body
          echo "### Official Download Links" > links.md
          echo "" >> links.md
          echo "| Filename | Official URL |" >> links.md
          echo "| :--- | :--- |" >> links.md
          while read -r link; do
            filename=$(basename "$link")
            echo "| $filename | [Download]($link) |" >> links.md
          done < links.txt

      - name: Install aria2
        run: sudo apt-get update && sudo apt-get install -y aria2

      - name: Download Installers
        run: |
          mkdir -p downloads
          # aria2 input file: each URL followed by output options
          > aria2_input.txt
          while read -r link; do
            filename=$(basename "$link")
            echo "$link" >> aria2_input.txt
            echo "  dir=downloads" >> aria2_input.txt
            echo "  out=$filename" >> aria2_input.txt
          done < links.txt

          echo "--- aria2 input file ---"
          cat aria2_input.txt
          echo "--- Starting parallel downloads ---"

          # -x16: 16 connections per file
          # -s16: split each file into 16 segments
          # -j$(wc -l < links.txt): download all files concurrently
          # -k1M: minimum split size 1MB
          # --file-allocation=none: no pre-allocation for speed
          JOBS=$(wc -l < links.txt)
          aria2c \
            --input-file=aria2_input.txt \
            --max-connection-per-server=16 \
            --split=16 \
            --min-split-size=1M \
            --max-concurrent-downloads=$JOBS \
            --file-allocation=none \
            --console-log-level=notice \
            --summary-interval=5

          echo "--- Download complete ---"
          ls -lh downloads/

      - name: Prepare Latest Files
        run: |
          VERSION=${{ steps.fetch_config.outputs.VERSION }}
          mkdir -p latest_files
          for file in downloads/*; do
            filename=$(basename "$file")
            # Robustly replace the version_build part with "latest"
            new_filename=$(echo "$filename" | sed -E 's/^QQ_.*_(amd64|x86_64|arm64|aarch64|loongarch64|mips64el)(_[0-9]+)\.(deb|rpm|AppImage)$/QQ_latest_\1\2.\3/')
            cp "$file" "latest_files/$new_filename"
          done

      - name: Read Release Body
        id: release_body
        run: |
          {
            echo 'BODY_CONTENT<<EOF'
            cat links.md
            echo EOF
          } >> "$GITHUB_OUTPUT"

      - name: Check if release exists
        id: check_release
        run: |
          VERSION=${{ steps.fetch_config.outputs.VERSION }}
          if gh release view "$VERSION" >/dev/null 2>&1; then
            echo "exists=true" >> $GITHUB_OUTPUT
            echo "Release $VERSION already exists. Skipping."
          else
            echo "exists=false" >> $GITHUB_OUTPUT
          fi
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Create Release
        if: steps.check_release.outputs.exists == 'false'
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.fetch_config.outputs.VERSION }}
          name: Linux QQ ${{ steps.fetch_config.outputs.VERSION }}
          files: |
            downloads/*
            latest_files/*
          body: |
            Automatically scraped latest Linux QQ installers.
            Version: ${{ steps.fetch_config.outputs.VERSION }}

            ${{ steps.release_body.outputs.BODY_CONTENT }}
          draft: false
          prerelease: false
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
